The main topic of this thesis is Partially Observable Markov Decision Processes (POMDPs).
The practical use of this model has been criticized in Introduction, 
however it sums up accurately the principal features of a robotic system.
Next, Possibility Theory is presented
in order to introduce Qualitative Possibilistic Markov Decision Processes ($\pi$-MDPs)
and Partially Observable ones ($\pi$-POMDPs) which are the starting point
of this work.

\subsection{Partially Observable Markov Decision Process} \label{section_POMDP}

\begin{figure}[!t]
\input{src/fig-pomdp}
\caption[Influence Diagram of a POMDP and its belief updating process]{
Influence Diagram of a POMDP and its belief updating process:
black circles represent successive system states $S_t$,
blue ones represent successive observations $O_t$,
red squares are selected actions $a_t$,
and yellow diamonds are the associated rewards.
Green circles at the top of the figure are the successive belief states 
$B_t$ constituting the belief updating process,
computed using the update $B_{t+1} = u(B_t,a_t,O_{t+1})$.
Just like the wavy lines leading to rewards, 
the green dotted lines represent a deterministic influence.
The Bayesian Network resulting from removing belief states and rewards, 
asserts that $\forall t \geqslant 1$, $S_{t+1} \perp\!\!\!\perp \set{ S_{0},S_1, O_1, \ldots, S_{t-1}, O_{t-1} } \vert \set{S_t,A_t}$,
where $A_t$ represents the action at time step $t$ seen as a random variable.
As well, $\forall t \geqslant 1$, $O_{t}$ is independent from all other variables 
conditional on $\set{S_t, A_t}$.}
\label{POMDP} 
\end{figure}

